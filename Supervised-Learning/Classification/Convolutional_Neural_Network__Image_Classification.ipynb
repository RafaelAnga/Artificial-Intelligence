{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RafaelAnga/Artificial-Intelligence/blob/main/Supervised-Learning/Classification/Convolutional_Neural_Network__Image_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DR-eO17geWu"
      },
      "source": [
        "# Convolutional Neural Network for Cat vs Dog Image Classification\n",
        "\n",
        "### Project Overview\n",
        "This project implements a Convolutional Neural Network (CNN) to classify images of cats and dogs.\n",
        "The model uses deep learning techniques to automatically learn and distinguish between images of these two animals,\n",
        "demonstrating the power of CNNs in computer vision tasks. This project is a classic example of binary image classification\n",
        "and showcases the use of TensorFlow and Keras for building and training CNNs.\n",
        "\n",
        "The dataset consists of labeled images of cats and dogs, divided into training and test sets.\n",
        "The CNN is trained to identify patterns in the images and predict whether a given image is of a cat or a dog.\n",
        "\n",
        "**Key Objectives:**\n",
        "1. Preprocess the dataset to make it suitable for training.\n",
        "2. Build a CNN with convolutional, pooling, and dense layers.\n",
        "3. Train the CNN on the training set and evaluate its performance on the test set.\n",
        "4. Make predictions on new images using the trained model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMefrVPCg-60"
      },
      "source": [
        "### Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCV30xyVhFbE"
      },
      "source": [
        "# Import required libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIleuCAjoFD8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "127a8ef2-0cb8-4919-e93c-24591a9df43e"
      },
      "source": [
        "# Checks tensorflow version\n",
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.18.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxQxCBWyoGPE"
      },
      "source": [
        "## Part 1 - Data Preprocessing\n",
        "Data preprocessing involves preparing the training and test datasets for the CNN.\n",
        "This includes rescaling pixel values, applying data augmentation to the training set,\n",
        "and ensuring the test set is properly scaled for evaluation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvE-heJNo3GG"
      },
      "source": [
        "### Preprocessing the Training set\n",
        "Apply data augmentation techniques like rescaling, shearing, zooming, and horizontal flipping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0koUcJMJpEBD"
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "training_set = train_datagen.flow_from_directory('dataset/training_set',\n",
        "                                                 target_size = (64, 64),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'binary')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrCMmGw9pHys"
      },
      "source": [
        "### Preprocessing the Test set\n",
        "Only rescale the test set without augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SH4WzfOhpKc3"
      },
      "source": [
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "test_set = test_datagen.flow_from_directory('dataset/test_set',\n",
        "                                            target_size = (64, 64),\n",
        "                                            batch_size = 32,\n",
        "                                            class_mode = 'binary')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "af8O4l90gk7B"
      },
      "source": [
        "## Part 2 - Building the CNN\n",
        "The CNN architecture consists of convolutional layers for feature extraction,\n",
        "pooling layers for dimensionality reduction, and dense layers for classification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ces1gXY2lmoX"
      },
      "source": [
        "### Initializing the CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAUt4UMPlhLS"
      },
      "source": [
        "cnn = tf.keras.models.Sequential()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5YJj_XMl5LF"
      },
      "source": [
        "### Step 1 - Convolution\n",
        "Add a convolutional layer with 32 filters, a 3x3 kernel, ReLU activation, and input shape of 64x64x3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPzPrMckl-hV"
      },
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tf87FpvxmNOJ"
      },
      "source": [
        "### Step 2 - Pooling\n",
        "Add a max pooling layer with a 2x2 pool size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncpqPl69mOac"
      },
      "source": [
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaTOgD8rm4mU"
      },
      "source": [
        "### Adding a second convolutional layer\n",
        "Add another convolutional layer with 32 filters and a 3x3 kernel, followed by a max pooling layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_-FZjn_m8gk"
      },
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmiEuvTunKfk"
      },
      "source": [
        "### Step 3 - Flattening\n",
        "Flatten the feature maps into a 1D vector for input to the dense layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AZeOGCvnNZn"
      },
      "source": [
        "cnn.add(tf.keras.layers.Flatten())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAoSECOm203v"
      },
      "source": [
        "### Step 4 - Full Connection\n",
        "Add a fully connected dense layer with 128 neurons and ReLU activation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GtmUlLd26Nq"
      },
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTldFvbX28Na"
      },
      "source": [
        "### Step 5 - Output Layer\n",
        "Add the output layer with 1 neuron and sigmoid activation for binary classification\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1p_Zj1Mc3Ko_"
      },
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6XkI90snSDl"
      },
      "source": [
        "## Part 3 - Training the CNN\n",
        "The CNN is compiled with the Adam optimizer, binary cross-entropy loss function,\n",
        "and accuracy as the evaluation metric. The model is trained on the training set\n",
        "and validated on the test set for 25 epochs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfrFQACEnc6i"
      },
      "source": [
        "### Compiling the CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NALksrNQpUlJ"
      },
      "source": [
        "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehS-v3MIpX2h"
      },
      "source": [
        "### Training the CNN on the Training set and evaluating it on the Test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUj1W4PJptta"
      },
      "source": [
        "cnn.fit(x = training_set, validation_data = test_set, epochs = 25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3PZasO0006Z"
      },
      "source": [
        "## Part 4 - Making a single prediction\n",
        "The trained CNN is used to make predictions on new images.\n",
        "The image is preprocessed to match the input format of the model,\n",
        "and the prediction is displayed as either 'cat' or 'dog'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsSiWEJY1BPB"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "# Load and preprocess a single image for prediction\n",
        "test_image = image.load_img('cat_or_dog_1.png', target_size = (64, 64))\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis = 0)\n",
        "\n",
        "# Make a prediction\n",
        "result = cnn.predict(test_image)\n",
        "training_set.class_indices\n",
        "\n",
        "# Interpret the prediction\n",
        "if result[0][0] == 1:\n",
        "  prediction = 'dog'\n",
        "else:\n",
        "  prediction = 'cat'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ED9KB3I54c1i"
      },
      "source": [
        "print(prediction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Project Summary\n",
        "**1. Technical Stack**\n",
        "  - Python 3.x\n",
        "  - TensorFlow and Keras\n",
        "  - Libraries: NumPy, ImageDataGenerator\n",
        "  - Development Environment: Google Colab\n",
        "\n",
        "**2. Dataset**\n",
        "  - The dataset contains labeled images of cats and dogs.\n",
        "  - Training and test sets are stored in separate directories.\n",
        "  - Images are resized to 64x64 pixels for input to the CNN.\n",
        "\n",
        "**3. CNN Architecture**\n",
        "  - Input Layer: Accepts 64x64x3 images.\n",
        "  - Convolutional Layers: Two layers with 32 filters each and ReLU activation.\n",
        "  - Pooling Layers: Max pooling with a 2x2 pool size.\n",
        "  - Flattening: Converts feature maps into a 1D vector.\n",
        "  - Dense Layers: One hidden layer with 128 neurons (ReLU) and an output layer with 1 neuron (sigmoid).\n",
        "\n",
        "**4. Model Training**\n",
        "  - Optimizer: Adam\n",
        "  - Loss Function: Binary Cross-Entropy\n",
        "  - Metrics: Accuracy\n",
        "  - Epochs: 25\n",
        "  - Batch Size: 32\n",
        "\n",
        "**5. Business Applications**\n",
        "  - Pet identification systems\n",
        "  - Animal shelter management\n",
        "  - Image-based search engines\n",
        "  - Educational abilities for image classification\n",
        "  - Demonstration of deep learning in computer vision\n",
        "\n",
        "This CNN model demonstrates the effectiveness of deep learning for binary image classification tasks.\n",
        "It can be further extended to classify more categories or applied to other computer vision problems."
      ],
      "metadata": {
        "id": "-Lt0lxOXw3f4"
      }
    }
  ]
}